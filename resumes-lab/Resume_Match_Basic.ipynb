{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "basic-intro",
            "metadata": {},
            "source": [
                "# Lab: AI-Powered Resume Matcher (BASIC VERSION)\n",
                "\n",
                "### **Objective**\n",
                "This lab demonstrates the \"shallow\" approach to resume matching using only **Keywords**. \n",
                "\n",
                "In recruitment tech, this is how many older ATS (Applicant Tracking Systems) work. It looks for exact word matches between a job description and a resume.\n",
                "\n",
                "### **Educational Goal**\n",
                "See how a high-quality resume can receive a **low score** simply because it uses different terminology than the job posting."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "setup",
            "metadata": {},
            "source": [
                "## Step 0: Setup\n",
                "\n",
                "We need to import our libraries and load our IBM Watson NLU credentials."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "from dotenv import load_dotenv\n",
                "from ibm_watson import NaturalLanguageUnderstandingV1\n",
                "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
                "from ibm_watson.natural_language_understanding_v1 import Features, KeywordsOptions\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "from sklearn.metrics.pairwise import cosine_similarity\n",
                "import fitz  # PyMuPDF\n",
                "\n",
                "# Load credentials\n",
                "load_dotenv()\n",
                "iam_key = os.getenv(\"IAM_KEY\")\n",
                "service_url = os.getenv(\"SERVICE_URL\")\n",
                "\n",
                "authenticator = IAMAuthenticator(iam_key)\n",
                "nlu = NaturalLanguageUnderstandingV1(version='2022-04-07', authenticator=authenticator)\n",
                "nlu.set_service_url(service_url)\n",
                "\n",
                "print(\"Setup complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "step1",
            "metadata": {},
            "source": [
                "## Step 1: Industry Keywords (Job Analysis)\n",
                "\n",
                "We will extract technical keywords from the job description file."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "job-analysis",
            "metadata": {},
            "outputs": [],
            "source": [
                "JOB_FILE = \"docs/job-5653.txt\"\n",
                "\n",
                "with open(JOB_FILE, 'r') as f:\n",
                "    job_text = f.read()\n",
                "\n",
                "job_response = nlu.analyze(\n",
                "    text=job_text,\n",
                "    features=Features(keywords=KeywordsOptions(limit=20))\n",
                ").get_result()\n",
                "\n",
                "job_keywords = [kw['text'] for kw in job_response.get('keywords', [])]\n",
                "print(f\"Extracted {len(job_keywords)} keywords from the Job Description.\")\n",
                "print(\"Top Job Keywords:\", job_keywords[:10])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "step2",
            "metadata": {},
            "source": [
                "## Step 2: Resume Keywords\n",
                "\n",
                "Now we extract keywords from the resume PDF."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "resume-analysis",
            "metadata": {},
            "outputs": [],
            "source": [
                "RESUME_PATH = \"docs/PortillaCV-08-2023.pdf\"\n",
                "\n",
                "def extract_text(path):\n",
                "    text = \"\"\n",
                "    with fitz.open(path) as doc:\n",
                "        for page in doc: text += page.get_text()\n",
                "    return text\n",
                "\n",
                "resume_text = extract_text(RESUME_PATH)\n",
                "resume_response = nlu.analyze(\n",
                "    text=resume_text,\n",
                "    features=Features(keywords=KeywordsOptions(limit=20))\n",
                ").get_result()\n",
                "\n",
                "resume_keywords = [kw['text'] for kw in resume_response.get('keywords', [])]\n",
                "print(f\"Extracted {len(resume_keywords)} keywords from the Resume.\")\n",
                "print(\"Top Resume Keywords:\", resume_keywords[:10])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "step3",
            "metadata": {},
            "source": [
                "## Step 3: The Shallow Match Result\n",
                "\n",
                "We use TF-IDF to calculate how many words overlap."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "match",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_score(kw1, kw2):\n",
                "    vectorizer = TfidfVectorizer()\n",
                "    matrix = vectorizer.fit_transform([' '.join(kw1), ' '.join(kw2)])\n",
                "    return round(cosine_similarity(matrix[0], matrix[1])[0][0] * 100, 2)\n",
                "\n",
                "match_score = get_score(job_keywords, resume_keywords)\n",
                "\n",
                "print(f\"\\nFINAL BASIC MATCH SCORE: {match_score}%\")\n",
                "\n",
                "plt.figure(figsize=(8, 2))\n",
                "plt.barh(['Keyword Overlap'], [match_score], color='salmon')\n",
                "plt.xlim(0, 100)\n",
                "plt.title(f'Basic Keyword Match: {match_score}%')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "basic-questions",
            "metadata": {},
            "source": [
                "### **Discussion Questions**\n",
                "1. Is this score lower than you expected? Why?\n",
                "2. Look at the Keyword lists. Are there synonyms (e.g., \"Leader\" vs \"Manager\") that the computer missed because they aren't *exact* matches?\n",
                "3. **What's Missing?** Now, open the **Advanced Lab** to see how Semantic Intelligence solves this problem."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}