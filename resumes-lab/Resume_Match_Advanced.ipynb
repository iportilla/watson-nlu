{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "advanced-intro",
            "metadata": {},
            "source": [
                "# Lab: AI-Powered Resume Matcher (ADVANCED SEMANTIC UPGRADE)\n",
                "\n",
                "### **Objective**\n",
                "This is the most advanced version of our recruitment AI lab. Here, we use four distinct \"Signals\" from **IBM Watson NLU** to evaluate a candidate just like a human recruiter would.\n",
                "\n",
                "### **The Four Semantic Signals**\n",
                "1. **Keywords (Shallow)**: Technical jargon and specific tools (e.g., \"Python\", \"React\").\n",
                "2. **Concepts (Deep)**: Abstract themes and expertise (e.g., \"Software Development Life Cycle\").\n",
                "3. **Entities (Proper Nouns)**: Companies, job titles, and specific organizations (e.g., \"IBM\", \"Staff Engineer\").\n",
                "4. **Categories (Context)**: The industry domain (e.g., \"Technology > Software Engineering\").\n",
                "\n",
                "### **Why this matters?**\n",
                "Keywords might only get you 10%, but your **Entities** and **Concepts** show you have the right background even if you didn't use the \"exact\" words the job poster chose."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "setup",
            "metadata": {},
            "source": [
                "## Step 0: Setup and Authentication"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "nlu-setup",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "from dotenv import load_dotenv\n",
                "from ibm_watson import NaturalLanguageUnderstandingV1\n",
                "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
                "from ibm_watson.natural_language_understanding_v1 import Features, KeywordsOptions, ConceptsOptions, CategoriesOptions, EntitiesOptions\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "from sklearn.metrics.pairwise import cosine_similarity\n",
                "import fitz  # PyMuPDF\n",
                "\n",
                "# Load credentials\n",
                "load_dotenv()\n",
                "iam_key = os.getenv(\"IAM_KEY\")\n",
                "service_url = os.getenv(\"SERVICE_URL\")\n",
                "\n",
                "authenticator = IAMAuthenticator(iam_key)\n",
                "nlu = NaturalLanguageUnderstandingV1(version='2022-04-07', authenticator=authenticator)\n",
                "nlu.set_service_url(service_url)\n",
                "\n",
                "print(\"Advanced Intelligence Setup Complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "step1",
            "metadata": {},
            "source": [
                "## Step 1: Quad-Feature Signal Extraction\n",
                "\n",
                "We will now extract Keywords, Concepts, Entities, and Categories from both documents."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "analysis-engine",
            "metadata": {},
            "outputs": [],
            "source": [
                "def analyze_document(text):\n",
                "    return nlu.analyze(\n",
                "        text=text,\n",
                "        features=Features(\n",
                "            keywords=KeywordsOptions(limit=25),\n",
                "            concepts=ConceptsOptions(limit=15),\n",
                "            entities=EntitiesOptions(limit=25),\n",
                "            categories=CategoriesOptions(limit=5)\n",
                "        )\n",
                "    ).get_result()\n",
                "\n",
                "def extract_pdf_text(path):\n",
                "    text = \"\"\n",
                "    with fitz.open(path) as doc:\n",
                "        for page in doc: text += page.get_text()\n",
                "    return text\n",
                "\n",
                "# Process Documents\n",
                "JOB_FILE = \"docs/job-5653.txt\"\n",
                "RESUME_FILE = \"docs/PortillaCV-08-2023.pdf\"\n",
                "\n",
                "with open(JOB_FILE, 'r') as f: job_text = f.read()\n",
                "resume_text = extract_pdf_text(RESUME_FILE)\n",
                "\n",
                "j_raw = analyze_document(job_text)\n",
                "r_raw = analyze_document(resume_text)\n",
                "\n",
                "print(\"Deep Extraction Complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "step2",
            "metadata": {},
            "source": [
                "## Step 2: Comparing the Signals\n",
                "\n",
                "We now calculate similarity across four dimensions, allowing us to see exactly where the candidate is a fit."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "scoring",
            "metadata": {},
            "outputs": [],
            "source": [
                "def list_sim(l1, l2):\n",
                "    if not l1 or not l2: return 0.0\n",
                "    v = TfidfVectorizer()\n",
                "    m = v.fit_transform([' '.join(l1), ' '.join(l2)])\n",
                "    return round(cosine_similarity(m[0], m[1])[0][0] * 100, 2)\n",
                "\n",
                "# Extract lists\n",
                "j_kw = [x['text'] for x in j_raw.get('keywords', [])]\n",
                "r_kw = [x['text'] for x in r_raw.get('keywords', [])]\n",
                "j_cp = [x['text'] for x in j_raw.get('concepts', [])]\n",
                "r_cp = [x['text'] for x in r_raw.get('concepts', [])]\n",
                "j_en = [x['text'] for x in j_raw.get('entities', [])]\n",
                "r_en = [x['text'] for x in r_raw.get('entities', [])]\n",
                "\n",
                "# Calculate Match Percentages\n",
                "kw_score = list_sim(j_kw, r_kw)\n",
                "cp_score = list_sim(j_cp, r_cp)\n",
                "en_score = list_sim(j_en, r_en)\n",
                "\n",
                "# Refined Category Match: Check for INDUSTRY overlap across all categories\n",
                "j_cats = [c['label'].split('/')[1] for c in j_raw.get('categories', []) if '/' in c['label']]\n",
                "r_cats = [c['label'].split('/')[1] for c in r_raw.get('categories', []) if '/' in c['label']]\n",
                "ct_score = 100 if set(j_cats).intersection(set(r_cats)) else 0\n",
                "\n",
                "# Quadrant weighted score\n",
                "final_score = round((kw_score * 0.3) + (cp_score * 0.3) + (en_score * 0.2) + (ct_score * 0.2), 2)\n",
                "\n",
                "print(f\"--- DIMENSIONAL ANALYSIS ---\")\n",
                "print(f\"Shard Keyword Score: {kw_score}%\")\n",
                "print(f\"Semantic Concept Score: {cp_score}%\")\n",
                "print(f\"Entity (Proper Name) Score: {en_score}%\")\n",
                "print(f\"Industry Category Score: {ct_score}%\")\n",
                "print(f\"\\nFINAL INTEGRATED MATCH SCORE: {final_score}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "step3",
            "metadata": {},
            "source": [
                "## Step 3: Visualization & Educational Insight\n",
                "\n",
                "This chart shows why the \"Basic Match\" was misleading. Even if the keywords are low, the **Concepts** and **Industry Context** prove the candidate is highly qualified."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "viz",
            "metadata": {},
            "outputs": [],
            "source": [
                "labels = ['Keywords', 'Concepts', 'Entities', 'Context', 'OVERALL']\n",
                "vals = [kw_score, cp_score, en_score, ct_score, final_score]\n",
                "colors = ['#ff9999','#66b3ff','#99ff99','#ffcc99', '#c1f1ec']\n",
                "\n",
                "plt.figure(figsize=(10, 5))\n",
                "plt.bar(labels, vals, color=colors)\n",
                "plt.ylim(0, 100)\n",
                "plt.ylabel('Match %')\n",
                "plt.title(f'Advanced Quad-Signal AI Comparison: {final_score}%')\n",
                "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "conclusion",
            "metadata": {},
            "source": [
                "### **Conclusion for Students**\n",
                "1. **Keywords**: ATS basics. Often low because of differing jargon.\n",
                "2. **Concepts**: Shows you \"know your stuff\" regardless of terms.\n",
                "3. **Entities**: Validates your career history (Recognizable companies & specific roles).\n",
                "4. **Category**: Validates that you are in the right professional industry."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}